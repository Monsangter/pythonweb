정적과 동적의 차이

            정적 크롤링          동적크롤링
크롤링 속도    빠르고 간단          느리고 복잡

크롤링시 작업 속도. 네이버 환율을 예로들면 정적크롤링은 바로 주소를 찌르게 됨. 그래서 속도가 간단.
동적 크롤링은 그 주소를 알아내고 찌르는 과정까지의 유저행동을 모방한다고 생각하면됨. 그래서 복잡

개발 편의성    처음엔 쉽지만 고도어렵  첨어렵고도 편리

정적 크롤링의 경우 만약 환율에 수수료계산까지 필요하다 그러면 정적크롤링은 시시각각 변하는 값을 가져오지는 못함.
동적 크롤링의 경우 코드가 엄청나게 길어질 수 있음. 다만 유저를 흉내내다보니 유저가 하는 모든 것을 해볼 수 잇음.

디버깅 편의성   테스트 쉬움          테스트 어려움

정적은 html 리스폰스와 리퀘스트만 보면 됨. 개발자 코드를 하나하나 수정하기 어렵다 뿐이지 봐야할 범위는 적음.
동적은 웹앱같은 경우는 초반에 로딩될때 데이터가 없을 수 잇음. 그런 부분에서 만약 로딩이 1초가 필요하다. 그러면 어려워짐. 즉 복잡한기계기 떄문에 문제해결 어려움

오류 취약점    상대적으로 낮음	      상대적으로 높음

페이지 레이아웃이 바뀌는 경우 정적크롤링은 대체해서 짜놓는게 어렵진 암ㅎ음.
정적 크롤링의 경우에는 레이아웃이 바뀌어도 데이터 자체를 가져올 수도 잇음.

하지만 동적크롤링은 그 숨겨짐에 민감함. 수많은 복병들이 숨겨져 잇음. 뭐 글 작성 임시 저장 기능처럼, 그냥 사용시 인지 못했던 부분이
동적 크롤링 시에는 문제가 될 수 있음. 따라서 동적크롤링이 오류에 민감하다.
정적은 또 어려운게 잇음.
정적으로 못가져오는 데이터가 있음. 실제 접속해 클릭해야되는데 그게 다 기록돼야 한다거나 주소를 알아내서 리퀘스트를 다 해야되는데 
그러기엔 로그인부터해서 브라우저에서 연산해주는 부분이 필요할 수도 있음. 
정적크롤링은 로그인을 막을 수도 있고 암호화 풀게 할 수도 있음. 그런데 정적 크롤링은 자스가 안댐! 그래서 암호 못품 뭐 사용할 수는 잇는데, 그냥 요즘은
그럴바엔 동적크롤링 씀.

동적크롤링이 좀더 주요하고 필수불가결하긴함.

========================
웹사이트 사전조사 - 크롬 개발자 도구
크롬브라우저는 개발자 친화도구를 가지고 있음.

원하는 데이터의 위치나 생김새등을 볼 수 있음.

-탭종류

elements
소스분석을 하지 않아도 원하는 데이터의 위치를 확인할 수 있음!

웹의 원소 최소단위를 분석
html구조 파악 가능.



console
자바스크립트를 실행하고 테스트 해볼 수 있음.
디버깅에 유리


sources
웹사이트가 불러와질때 css, js파일등 어떤걸 불러왔는지 표시해줌.

network
웹사이트가 로딩된 이후 주고 받는 모든 패킷등을 감시.

performance
사이트 로딩시 얼마의 시간이 걸렸나?

녹화버튼누르고 행위하다 중단하면 캡쳐해서 볼 수도 있음

application
고도화된 크롤링 시
쿠키에 관련한 부분.

웹페이지가 사용중이던 저장소에 관련한 부분.

페이지도 어느정도 우리 기기 캐시에 저장해서 사용하게 됨.
자주 사용하는 정보나 쿠키 같은 것들.

그래서 확인하고 필요시 꺼내 사용 가능

-크롬 개발자 도구 핵심
element 탭에서 원하는 데이터 구조 위치 파악후
console 탭에서 테스트 해보기


==========
request 라이브러리 소개

python익스텐션



구글에 requests검색 

quickstart 들어가보면 설치법 있음.

사람들이 많이 사용하는 라이브러리 같은 경우는 업데이트가 잦음. 알아서 공식문서 보고 배우삼


-주요함수

import requests

res = requests.get("https://www.naver.com/")
print(res.text)

###
#get: 요청 값 가져오는 역할
#post: 생성, 액션
#put : 수정 덮어씌우기
#delet: 삭제

#GET / HTTP/1.1
#Host: www.naver.com
#사용자에 편리한 기능들이 다르게 들어가 있긴 하지만  다른 것들도 장독.

#text
#json() 만약 text파일이 제이슨으로 돼 잇으면 사용할 수 있게 해줌.

=======
get 접속해보기

210.14.73.16

웹 상에서의 고유한 이름



import requests as req

#response=>res
#alias가 아닌 http에서 의 요청도 줄일때 req
#requests=>req

#headers로 헤더도 보낼 수 있음.
res = req.get("https://api.ipify.org/", headers={"fast": "campus"})
print(res.request.method)
print(res.request.headers)
print(res.status_code)
print(res.text)
print(res.elapsed)
#실제 객체의 바이트값
#주가는 수치로 가져올수있지만 이미지나 영상을 파싱하고 싶을때 필요.
#raw는 컴퓨터에서 거의 바이트를 뜻함. 컴퓨터에서 자료가저장되는 가장 작은단위가
#바이트 이기 때문.
print(res.raw)


#왜 터미널에서는 html태그를 반환해주지 않고 ip주소만 반환해줄까 ?
#리퀘스트로 접속할때와 브라우저 개발자 도구에서 다른 이유는 
#1. http요청을 서버에 날릴시 해당 문자열을 서버에서 해석해 응답을 줌.
#서버는 클라이언트의 요청값, 모습에따라 다른 분석값을 줄 수 있음.
#같은 pc에서 리퀘스트를 이용하더라도 브라우저에는 html 에 많은 값을 추가적으로 보냄

#2. 크롬. 브라우저에서
#개발자도구는 서버에서 응답받은 ip글자만 보여줬는데 
#브라우저가 민망해서 간단히 html을 채운거임.
#우클릭해서 페이지 소스보기하면 html 하나도 없음.

